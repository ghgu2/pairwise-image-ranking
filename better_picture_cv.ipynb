{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Библиотеки"
      ],
      "metadata": {
        "id": "HlcdNOFUPOWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "import glob\n",
        "import timm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "E1D9C47ePTON"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Данные"
      ],
      "metadata": {
        "id": "BAb0ZOO-PXnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"models\", exist_ok=True)\n",
        "os.makedirs(\"submits\", exist_ok=True)"
      ],
      "metadata": {
        "id": "tBylkBLJh7ju"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDJtxZ17Qz0F",
        "outputId": "e9e9025f-0443-4814-c32f-a3507db3a26f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv(\"/content/drive/MyDrive/CV/sample_submission.csv\")\n",
        "df_train = pd.read_parquet(\"/content/drive/MyDrive/CV/train.parquet\")\n",
        "df_test = pd.read_parquet(\"/content/drive/MyDrive/CV/test.parquet\")"
      ],
      "metadata": {
        "id": "Iix-e5bHQkaH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train shape:\", df_train.shape)\n",
        "print(\"test shape :\", df_test.shape)\n",
        "print(\"sample_submission shape:\", sample_submission.shape)\n",
        "\n",
        "df_train.head(2)"
      ],
      "metadata": {
        "id": "63a71b2vTsMo"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 10\n",
        "\n",
        "row = df_train.iloc[idx]\n",
        "print(f\"is_image1_better = {row.get('is_image1_better', None)}\")\n",
        "\n",
        "img1_bytes = row[\"image_1\"].tobytes() if isinstance(row[\"image_1\"], memoryview) else row[\"image_1\"]\n",
        "img2_bytes = row[\"image_2\"].tobytes() if isinstance(row[\"image_2\"], memoryview) else row[\"image_2\"]\n",
        "\n",
        "img1 = Image.open(io.BytesIO(img1_bytes)).convert(\"RGB\")\n",
        "img2 = Image.open(io.BytesIO(img2_bytes)).convert(\"RGB\")\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "ax[0].imshow(img1)\n",
        "ax[0].axis(\"off\")\n",
        "ax[0].set_title(\"image_1\")\n",
        "\n",
        "ax[1].imshow(img2)\n",
        "ax[1].axis(\"off\")\n",
        "ax[1].set_title(\"image_2\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ivXqjnUSQo1I"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание класса Dataset для картинок"
      ],
      "metadata": {
        "id": "-GJKV6DfWM1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IPDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        img1_bytes = row[\"image_1\"].tobytes() if isinstance(row[\"image_1\"], memoryview) else row[\"image_1\"]\n",
        "        img2_bytes = row[\"image_2\"].tobytes() if isinstance(row[\"image_2\"], memoryview) else row[\"image_2\"]\n",
        "\n",
        "        img1 = Image.open(io.BytesIO(img1_bytes)).convert(\"RGB\")\n",
        "        img2 = Image.open(io.BytesIO(img2_bytes)).convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "        if \"is_image1_better\" in self.df.columns:\n",
        "            y = torch.tensor(row[\"is_image1_better\"], dtype=torch.float32)\n",
        "            return img1, img2, y\n",
        "\n",
        "        return img1, img2"
      ],
      "metadata": {
        "id": "M_V80AWSWM8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Архитектура модели"
      ],
      "metadata": {
        "id": "MjRZd5OHTDe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Mymodel(nn.Module):\n",
        "    def __init__(self, freeze_encoder=True):\n",
        "        super().__init__()\n",
        "        self.encoder = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)\n",
        "\n",
        "        if freeze_encoder:\n",
        "            for p in self.encoder.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "\n",
        "        self.encoder.head = nn.Identity()\n",
        "        self.rank_head = nn.Linear(768, 1)\n",
        "\n",
        "        self.classifier_head = nn.Sequential(\n",
        "            nn.Linear(768 * 4, 2048),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.4),\n",
        "\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img1, img2, return_embeddings=False):\n",
        "      features1 = self.encoder(img1)\n",
        "      features2 = self.encoder(img2)\n",
        "\n",
        "      if return_embeddings:\n",
        "        return self.encoder(img1), self.encoder(img2)\n",
        "      features1 = features1.mean(dim=(1, 2))\n",
        "      features2 = features2.mean(dim=(1, 2))\n",
        "\n",
        "      diff = features1 - features2\n",
        "      mul = features1 * features2\n",
        "      combined = torch.cat((features1, features2, diff, mul), dim=1)\n",
        "\n",
        "      output = self.classifier_head(combined)\n",
        "      return output"
      ],
      "metadata": {
        "id": "v8ApVBq4Qo55"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение модели"
      ],
      "metadata": {
        "id": "rb1pqqtfWrhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images1, images2, labels in tqdm(dataloader, desc=\"Training\"):\n",
        "        images1, images2, labels = images1.to(device), images2.to(device), labels.to(device)\n",
        "\n",
        "        features1, features2 = model(images1, images2, return_embeddings=True)\n",
        "\n",
        "        score1 = model.rank_head(features1).mean(dim=(1, 2, 3))\n",
        "        score2 = model.rank_head(features2).mean(dim=(1, 2, 3))\n",
        "\n",
        "        score_diff = score1 - score2\n",
        "\n",
        "        loss = F.binary_cross_entropy_with_logits(\n",
        "            score_diff,\n",
        "            labels.squeeze().float()\n",
        "          )\n",
        "        preds = (score_diff > 0)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images1.size(0)\n",
        "\n",
        "        correct_predictions += (preds == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = correct_predictions / total_samples\n",
        "    return model, epoch_loss, epoch_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "OkN1naazT6B_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval модели"
      ],
      "metadata": {
        "id": "jIuNVEYgWu6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    all_preds_logits = []\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images1, images2, labels in tqdm(dataloader, desc=\"Eval\"):\n",
        "            images1, images2, labels = (\n",
        "                images1.to(device),\n",
        "                images2.to(device),\n",
        "                labels.to(device)\n",
        "            )\n",
        "\n",
        "            features1, features2 = model(images1, images2, return_embeddings=True)\n",
        "\n",
        "            score1 = model.rank_head(features1).mean(dim=(1, 2, 3))\n",
        "            score2 = model.rank_head(features2).mean(dim=(1, 2, 3))\n",
        "            score_diff = score1 - score2\n",
        "\n",
        "            loss = F.binary_cross_entropy_with_logits(score_diff, labels.squeeze().float())\n",
        "            preds = (score_diff > 0)\n",
        "            preds_logits = score_diff\n",
        "\n",
        "\n",
        "            running_loss += loss.item() * images1.size(0)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            all_preds_logits.append(preds_logits.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = correct_predictions / total_samples\n",
        "    all_preds_logits = torch.cat(all_preds_logits)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    preds_proba = torch.sigmoid(all_preds_logits).numpy()\n",
        "    auc_score = roc_auc_score(all_labels.numpy(), preds_proba)\n",
        "\n",
        "    return epoch_loss, epoch_acc, auc_score, all_preds_logits, all_labels\n"
      ],
      "metadata": {
        "id": "GfbT0YGrT6Ef"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EarlyStopping для kfold валидации"
      ],
      "metadata": {
        "id": "_gGZT-ORXEar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0.0, path='checkpoint.pth'):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "        self.best_score = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, score, model):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model)\n",
        "            return\n",
        "\n",
        "        if score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} из {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "            self.save_checkpoint(model)\n",
        "\n",
        "    def save_checkpoint(self, model):\n",
        "        torch.save(model.state_dict(), self.path)"
      ],
      "metadata": {
        "id": "M32HPuduXEhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kfold cross validation"
      ],
      "metadata": {
        "id": "bQby1iqKW1vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kfold_cross_validation(df, dataset_class,\n",
        "                          num_folds=5, num_epochs=50, batch_size=16,\n",
        "                          patience=5, min_delta=0.001, pretrain_with_ranking=True, exp_time=''):\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "    df['fold'] = -1\n",
        "    for fold, (_, val_idx) in enumerate(skf.split(df, df['is_image1_better'])):\n",
        "        df.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "    results = []\n",
        "\n",
        "    experiment_dir = f'./models/exp_{exp_time}'\n",
        "    stage1_dir = os.path.join(experiment_dir, 'stage1')\n",
        "    stage2_dir = os.path.join(experiment_dir, 'stage2')\n",
        "    os.makedirs(stage1_dir, exist_ok=True)\n",
        "    os.makedirs(stage2_dir, exist_ok=True)\n",
        "\n",
        "    for fold in range(num_folds):\n",
        "        print(f\"\\n--- Fold {fold+1}/{num_folds} {datetime.now().strftime('%y-%m-%d %H:%M:%S')} ---\")\n",
        "\n",
        "        train_df = df[df['fold'] != fold]\n",
        "        val_df = df[df['fold'] == fold]\n",
        "        train_dataset = dataset_class(train_df.reset_index(drop=True), transform=train_transforms)\n",
        "        val_dataset = dataset_class(val_df.reset_index(drop=True), transform=val_transforms)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            persistent_workers=False,\n",
        "            num_workers=6,\n",
        "            pin_memory=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            persistent_workers=False,\n",
        "            num_workers=6,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        print(\"Stage 1: Pretraining encoder\")\n",
        "        model = Mymodel(freeze_encoder=False).to(device)\n",
        "        model_name = model.encoder._get_name()\n",
        "\n",
        "        criterion_stage1 = None\n",
        "        optimizer_stage1 = optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=LEARNING_RATE,\n",
        "            weight_decay=0.01\n",
        "            )\n",
        "\n",
        "        early_stopping_stage1 = EarlyStopping(\n",
        "            patience=patience,\n",
        "            verbose=True,\n",
        "            delta=min_delta,\n",
        "            path=os.path.join(stage1_dir, f\"stage1_fold{fold}_{exp_time}.pth\")\n",
        "            )\n",
        "        best_auc_stage1 = 0.0\n",
        "        for epoch in range(num_epochs):\n",
        "          model, train_loss, _ = train_model(\n",
        "              model, train_loader, criterion_stage1, optimizer_stage1, device,\n",
        "          )\n",
        "          val_loss, val_acc, auc_score, _, _ = evaluate_model(\n",
        "              model, val_loader, criterion_stage1, device\n",
        "          )\n",
        "          print(f\"Stage1 Epoch {epoch+1} - Val AUC: {auc_score:.4f}\")\n",
        "          early_stopping_stage1(auc_score, model)\n",
        "          if auc_score > best_auc_stage1:\n",
        "            best_auc_stage1 = auc_score\n",
        "            stage1_model_path = os.path.join(\n",
        "                stage1_dir,\n",
        "                f\"{model_name}_fold{fold}_{exp_time}.pth\"\n",
        "                )\n",
        "            torch.save(model.state_dict(), stage1_model_path)\n",
        "          best_auc_stage1 = max(best_auc_stage1, auc_score)\n",
        "          if early_stopping_stage1.early_stop:\n",
        "            break\n",
        "\n",
        "        print(\"Stage 2: Training classifier head\")\n",
        "        model = Mymodel(freeze_encoder=True).to(device)\n",
        "        model.load_state_dict(torch.load(stage1_model_path))\n",
        "        model.encoder.requires_grad_(False)\n",
        "\n",
        "        criterion_stage2 = nn.BCEWithLogitsLoss()\n",
        "        optimizer_stage2 = optim.AdamW(\n",
        "            model.classifier_head.parameters(),\n",
        "            lr=LEARNING_RATE,\n",
        "            weight_decay=0.01\n",
        "            )\n",
        "\n",
        "        early_stopping_stage2 = EarlyStopping(\n",
        "            patience=patience,\n",
        "            verbose=True,\n",
        "            delta=min_delta,\n",
        "            path=os.path.join(stage2_dir, f\"stage2_fold{fold}_{exp_time}.pth\")\n",
        "            )\n",
        "        best_auc_stage2 = 0.0\n",
        "        for epoch in range(num_epochs):\n",
        "          model, train_loss, train_acc = train_model(\n",
        "              model, train_loader, criterion_stage2, optimizer_stage2, device\n",
        "          )\n",
        "          val_loss, val_acc, auc_score, _, _ = evaluate_model(\n",
        "              model, val_loader, criterion_stage2, device\n",
        "          )\n",
        "          print(f\"Stage2 Epoch {epoch+1}\")\n",
        "          print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "          print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, AUC: {auc_score:.4f}\")\n",
        "          early_stopping_stage2(auc_score, model)\n",
        "          if auc_score > best_auc_stage2:\n",
        "            best_auc_stage2 = auc_score\n",
        "            stage2_model_path = os.path.join(\n",
        "                stage2_dir,\n",
        "                f\"{model_name}_fold{fold}_{exp_time}.pth\"\n",
        "                )\n",
        "            torch.save(model.state_dict(), stage2_model_path)\n",
        "          if early_stopping_stage2.early_stop:\n",
        "            break\n",
        "        results.append(best_auc_stage2)\n",
        "        print(f\"Best AUC on Fold {fold+1}: {best_auc_stage2:.4f}\\n\")\n",
        "\n",
        "        del model\n",
        "        del train_loader\n",
        "        del val_loader\n",
        "        time.sleep(1)\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    print(\"Результаты по фолдам:\", results)\n",
        "    print(\"Среднее AUC:\", np.mean(results))\n",
        "    return np.mean(results)\n",
        "\n"
      ],
      "metadata": {
        "id": "2L6mrwNmT6Gn"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функции для предсказания"
      ],
      "metadata": {
        "id": "H1FCto-TW9nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_for_inference_ranknet(model_path, device):\n",
        "    model = Mymodel(freeze_encoder=True).to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_ranknet_probs(model, test_loader, device):\n",
        "    all_probs = []\n",
        "    for images1, images2 in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        images1 = images1.to(device)\n",
        "        images2 = images2.to(device)\n",
        "        logits = model(images1, images2)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "    return np.array(all_probs)"
      ],
      "metadata": {
        "id": "HqQiDyXRT6Iv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Используемое устройство: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPUUTdJ2YTqC",
        "outputId": "cbad810a-d727-45b7-f262-79d24139fb3f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Агументации"
      ],
      "metadata": {
        "id": "dwY_dGeagifa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "hjsZjd1BYT3W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Кросс валидация"
      ],
      "metadata": {
        "id": "bpdc9d9Ygnqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 8\n",
        "\n",
        "train_dataset = IPDataset(df_train, transform=train_transforms)\n",
        "test_dataset = IPDataset(df_test, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    persistent_workers=False,\n",
        "    num_workers=6,\n",
        "    pin_memory=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    persistent_workers=False,\n",
        "    num_workers=6,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "experiment_time = datetime.now().strftime(\"%y%m%d%H%M%S\")"
      ],
      "metadata": {
        "id": "A9BEmKMPgeCG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score = kfold_cross_validation(\n",
        "    df=df_train,\n",
        "    dataset_class=IPDataset,\n",
        "    patience=2,\n",
        "    num_folds=5,\n",
        "    num_epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    pretrain_with_ranking=True,\n",
        "    exp_time=experiment_time,\n",
        ")"
      ],
      "metadata": {
        "id": "XdXzgz4-X-Ve"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предсказания test"
      ],
      "metadata": {
        "id": "Wrsga8knOUpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = IPDataset(df_test, transform=val_transforms)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    persistent_workers=False,\n",
        "    num_workers=6,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "ranknet_dir = f\"models/exp_{experiment_time}/stage2\"\n",
        "model_paths = sorted(glob.glob(os.path.join(ranknet_dir, \"*.pth\")))\n",
        "\n",
        "all_fold_probs = []\n",
        "for p in model_paths:\n",
        "    model = load_model_for_inference_ranknet(p, device)\n",
        "    probs = predict_ranknet_probs(model, test_loader, device)\n",
        "    all_fold_probs.append(probs)\n",
        "\n",
        "final_probs = np.mean(all_fold_probs, axis=0)\n",
        "final_preds = (final_probs > 0.5).astype(int)\n",
        "\n",
        "os.makedirs(f\"models/exp_{experiment_time}\", exist_ok=True)\n",
        "\n",
        "os.makedirs(\"submits\", exist_ok=True)"
      ],
      "metadata": {
        "id": "jZ46DwDCYB9l"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Формирование сабмита"
      ],
      "metadata": {
        "id": "-WfIt57f7BJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\"is_image1_better\": final_probs.reshape(-1)})\n",
        "submission.index.names = [\"index\"]\n",
        "submit_path = f\"submits/submission_{experiment_time}.csv\"\n",
        "submission.to_csv(submit_path, index=True)"
      ],
      "metadata": {
        "id": "_a6d0h4RyaK6"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NapilLjXXtYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}